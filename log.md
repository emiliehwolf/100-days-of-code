# 100 Days Of Code - Log

### Day 0.0: May 10, 2017

**Today's Progress:** Created #100DaysOfCode Challenge in my Data Scientists party on Habitica. We officially begin on Monday, May 15th. Logged into Kaggle.com and HackerRank.com to get an overview of the lessons and competitions. Also browsed FreeCodeCamp.com/map

**Thoughts:** Kaggle seems the most specialized for data science, but I still need to learn more R Programming before I'm ready for Kaggle. I think I will use my library book, R in 24 Hours, and my Coursera lessons as my curriculum. I will also continue to study R vocabulary on Memrise to keep things interesting and avoid monotony.

**Link to first tweet** [First tweet about challenge](https://twitter.com/emhunts/status/862647972621844480)


### Day 0.1: May 11, 2017 

**Today's Progress:** Listened to "Not So Standard Deviations" podcast while copying down common R functions from Memrise. New Habitica party member Daralysis joined today, so I saved the last 7 days of chat log in a Google doc so I won't forget all their names and introductions. Finally, completed several SWIRL lessons for Coursera and perused the first graphics chapter in my book, R in 24 Hours.

**Thoughts:** The Swirl lesson "Working with Colors" introduced me to several new functions: colorRamp(), colorRampPallete(), rgb(), and brewer.pal() from the RColorBrewer package. colorRampPallete() takes 2 colors and integer n and the result is a vector of colors of length n that are between the min and max you specified. This will be extremely helpful when I need to make a range of 366 colors for the publication of my dream journal. I remember I used Google Spreadsheet to come up with these colors and it took a long time. Now I know a much faster way to get these colors if I decide to change the ranges or the opacity!

**Links:** 
1. [Chart on the History of Programming Languages](http://www.digibarn.com/collections/posters/tongues/ComputerLanguagesChart.png)
2. [Working with Colors in R Tutorial](https://github.com/DataScienceSpecialization/courses/blob/master/04_ExploratoryAnalysis/Colors/index.Rmd)


### Day 1: May 15, 2017, Monday

**Today's Progress:** Today I entered in much of the practice code from Chapter 14 of my library book (R in 24 Hours). I saved all the plots and the Rhistory and uploaded them to GitHub using SourceTree. I ended up working for 1.5 hours. 

**Thoughts:** Next I'll make a nice markdown file in the repo and display the plots so I'll have a quick reference guide.

**Link to work:** [ggplot2_examples](https://github.com/emiliehwolf/ggplot2_examples)

### Day 2: May 16, 2017, Tuesday, 3:30AM

**Today's Progress:** Created markdown file to display ggplot2 quick plot examples from my library book, R in 24 Hours.

**Thoughts:** Not sure if this counts for the next day since I haven't slept yet. Oh well. I think my markdown file looks very nice and can probably be transformed into HTML pretty easily. I can't wait to finish the chapter in my book with all the ggplot() examples

**Link to latest commit:** [ggplot2 examples](https://github.com/emiliehwolf/ggplot2_examples/tree/37d2d3d654454eadb2d3006c43358283c7017823)

### Day 3: May 17, 2017, Wednesday, 5:00AM

**Today's Progress:** Finished creating my study guide from chapter 14 of my library book, R in 24 Hours.

**Thoughts:** Can't stop, won't stop. Was surprised to find out pie charts are discouraged in R. Eager to do the Quiz and Activities section for this chapter tomorrow.

**Link to latest commit:** [ggplot2_examples](https://github.com/emiliehwolf/ggplot2_examples/tree/700b1207cb143addba360e99b5d50b26a580985f)

### Day 4: May 18, 2017, Thursday, 11:57PM

**Today's Progress:** Added the 6 Activities to the study guide on my GitHub! Now watching the lecture videos for this week's Coursera.

**Thoughts:** I learned how to use the randomcoloR library to make unique color palettes.

**Link to latest commit:** [ggplot2_examples](https://github.com/emiliehwolf/ggplot2_examples/tree/bdd38f9db67f192ded5b65c4b0cc340282877d34)

### Day 5: May 19, 2017, Friday, 4:08PM

Today I worked through the 3 lecture videos on Clustering from Exploratory Data Analysis and practiced entering all the code from the tutorial. I basically got the same plots and results from this [study guide here](https://github.com/DataScienceSpecialization/courses/blob/master/04_ExploratoryAnalysis/hierarchicalClustering/index.md). 
Tonight and this weekend I need to finish the rest of Week 3 videos and Swirl practice exercises so I will be ready for the difficult assignment for week 4. All these statistical techniques are useful to know and I shouldn't stress so much about comprehending them fully, but rather just be familiar with them so I know where to get the answers should the question arise.

### Day 6: May 21, 2017, Sunday, 2:36AM

Plodding away on the remaining lecture videos and SWIRL practice assignments for Week 3 of Exploratory Data Analysis. Wish I could have gotten more done the last few days, but my personal life was more important. Will stay on track!

### Day 7, May 22, 2017, Monday, 3:25AM

Finished the SWIRL tutorials on Hierarchical Clustering, K-Means Clustering, Dimension Reduction, and a real-world clustering example. [Here's a link to the tutorial on GitHub.](https://github.com/DataScienceSpecialization/courses/blob/master/04_ExploratoryAnalysis/clusteringExample/index.md)

### Day 8, May 25, 2017, Thursday, 1:08AM

**Today's Progress:** Today I looked through my library book, R in 24 Hours, for any reference to clustering, kmeans, imputing, or dimension reduction. No such luck. Next I went for a walk to the grocery store and listened to [Not So Standard Deviations Episode 11](https://soundcloud.com/nssd-podcast/episode-11-start-and-stop) along the way and back. Once I came home, I worked on a business article for LinkedIn and got swept away editing. Finally I realized I was over-editing and decided to not work on it again until I had slept. Now I'm lying in bed watching the [Air Pollution Case Study video](https://www.coursera.org/learn/exploratory-data-analysis/lecture/hVteM/air-pollution-case-study) and following along the [R script analysis](https://github.com/DataScienceSpecialization/courses/blob/master/04_ExploratoryAnalysis/CaseStudy/script.R).

**Thoughts:** I really enjoyed the podcast today as I walked. It was a gorgeous day with lots of sun and the podcast was about Roger and Hilary's answer to the question, What's the first thing you do for a data analysis? Hilary starts by tidying the data and then applies it to the "Hadley-verse" (Hadley Wickam is the author of many specialized R packages). Roger starts by wrangling missing data (NA's) and then usually goes straight into modeling (regression?). They discussed whether or not they prefer boxplots or overlaying histograms when doing basic exploratory plots.

### Day 9, May 25, 2017, Thursday, 11:02PM

**Today's Progress:** I finished going through the Air Pollution Case Study from yesterday and I uploaded the analysis script with tons and tons of comments so I can always look back and understand it.

**Thoughts:** Lazy day for me. I'm curious and want to keep learning.

**Link to today's work:** [pm25 analysis with comments](https://github.com/emiliehwolf/pm25_data_casestudy/blob/master/pm25analysis.R)

# Day 10, May 27, 2017, Saturday, 1:19AM

**Today's Progress:** Today I worked on the final assignment for the Exploratory Data Analysis class. We are supposed to analyze the PM2.5 Emissions data from NEI and create plots that show whether or not emissions have decreased based on different criteria. I finished the first 3 plots (and in fact, I did the 3rd plot 3 different ways).

**Thoughts:** I like tackling these questions by first drawing on paper the kind of graphs and data tables I expect to have. Then I play around in R to manipulate the data and plot it. I still find myself forgetting function names and arguments, but as long as I have a rough idea of what steps to take, I can usually find the code on StackOverflow.

**Link to latest commit:** [EDA_Wk4Assignment](https://github.com/emiliehwolf/EDA_Wk4Assignment/blob/0e052ba382393dc8c6122d1be85a41b90e174876/pm25analysis.R)

### Day 11, Saturday, May 27, 2017, 7:00PM
All I did today was go for an hour walk and listen to episodes 13 and 14 of the Not So Standard Deviations podcast

### Day 12, Sunday, May 28, 2017, 12:42PM
I didn't code for just 1 hour... more like 5. I've been up since early this morning and finished my final assignment for Exploratory Data Analysis on Coursera. Now I just need to review the work of 4 other students...

**Link to Project:** [EDA_Wk4Assignment](https://github.com/emiliehwolf/EDA_Wk4Assignment)

### Day 13, Thursday, June 1, 2017, 9:29PM
Yeah, so I didn't code for 3 days in a row. It was Memorial Day and I needed to celebrate with family and then rest. Today I started a bunch of new dailies on Habitica and listened to episode 15 of Not So Standard Deviations. It was a good episode about collaboration software, communication, and GitHub flow (using issues as to-do's and branches for new code, even when working alone). Then later I created a nice markdown file for the assignment project I finished last coding session. [Now you can view code and plots together like a tutorial.](https://github.com/emiliehwolf/EDA_Wk4Assignment/blob/master/README.md)

### Day 14, Saturday, June 3, 2017, 1:28AM
Today I reviewed core R functions and explored the R environment. As I looked over the thousands of objects in the base R package, I felt amused that many were familiar to me and yet many more were not. I am saving my R exploration as a markdown file so I can always go back and view. Here is today's version: https://github.com/emiliehwolf/Rin24Hours/blob/ae2d3ca1277e2f04fefe7fc9c773e31bf4f2526f/readme.md

Tomorrow I hope to blaze through more of my library book and solidify my knowledge of the basics. I know I'm still a little unsure about functions like apply, tapply, sapply, and mapply.

### Day 15 and 16, Monday, June 5, 2017, 1:45AM
Yesterday and today was all research. I reviewed all my data science links that I've been collecting in a Google word document since January and moved them to dropmark.com for better accessibility. I should have saved the links in a Google spreadsheet document now that I think about it, but as luck would have it, dropmark.com let's you download your data in a nice table in several formats, including CSV. Many of these saved links I stumbled onto during my Coursera lessons, but I did not have the time to read them initially. As I reviewed the bookmarks one by one, I came across plots and R code from other data scientists and I had a good look. It's very fun perusing other people's open-source code on GitHub. :D I also challenged myself to some R function flashcards on my Memrise app on my phone. I also listened to more data science podcasts.

R is a very powerful, free tool and it's worth the investment of time to learn it. It can read all kinds of data and provide valuable insight! And thanks to a member in my Habitica party, I found a website called datasketch.es that is the EXACT type of work I'm trying to produce; interactive data in a webpage! The more I read about the process behind the visualizations, the more I finally understood the connections. I know HTML, CSS, and SVG. I had a hunch they were using JavaScript, and then I saw mention of D3.js again. If I want to create similar graphics, I will need to learn JavaScript... or at least relearn the basics and the D3 package.

I can start on w3schools.com to learn JS, and while I'm at it, I may as well learn Bootstrap for mobile-ready websites! THEEEN, once I know how to create out-of-this-world visualizations of big data, I can learn how to build apps and complete my dream app. Wow! That's a lot of work! Or maybe I can partner with others up to the challenge if I can convince them this is a fun model. 

### Day 17 and 18, Tuesday, June 6, 2017, 10:45PM
Yesterday and today was all review. I finished uploading all my links to dropmark.com. Booyakasha!

**Link to LINKS:** http://emiliehwolf.dropmark.com/427669

### Day 19, Monday, June 12, 2017, 11:12PM
I reviewed the chapter on loops and apply functions in R in 24 Hours. I returned the book, but will continue to try and make study guides.

I also tried to find an online R console for practice. http://www.r-fiddle.org/ can display plots and seems promising, so I added it to my dropmark. The next best available console was https://www.tutorialspoint.com/execute_r_online.php but I couldn't find a graphics display. Maybe it has to actually save a file to a graphics device before you can see the graphics.

Tomorrow's another day.

### Day 20, Tuesday, June 13, 2017, 10:50PM
Most of my things are packed, and I don't even have a desk to sit at right now. I spent my hour today optimizing photos I took of my library book so I can easily access the material in the future. I expect to be approved for the next Coursera class soon.

### Day 21, Friday, June 16, 2017, 8:19PM
**Today's Progress:** The last couple of days were moving days. Today I woke up in my new place, fixed my bicycle, and secured a job interview for next week (not data science related however). For my one hour of coding, I started watching the lectures for Week 1 of Reproducible Research and saved any pertinent links to my dropmark. 

**Thoughts:** Reproduciblity seems to be tied to workflow and documenting all the steps. I think I've already been doing this during programming assignments throughout the classes and when I make study guides, but the way I'm doing it now is probably slower than it should be. I hope to soon learn R Markdown and quickly and easily convert it to HTML or Github markdown. Not sure what the package knitr does, but I hope it makes documenting my analysis much easier in the coming weeks.

**Links to similar topics:** http://emiliehwolf.dropmark.com/427669/10734737 http://emiliehwolf.dropmark.com/427669/10718231

### Day 22, Tuesday, June 20, 2017, 2:50AM
More on reproducible research.
https://github.com/rdpeng/courses/blob/master/05_ReproducibleResearch/ReproducibleResearchConcepts/ReproResearch.pdf
https://github.com/rdpeng/courses/blob/master/05_ReproducibleResearch/structureOfADataAnalysis1/index.md
https://github.com/rdpeng/courses/blob/master/05_ReproducibleResearch/structureOfADataAnalysis2/index.md
https://github.com/rdpeng/courses/blob/master/05_ReproducibleResearch/organizingADataAnalysis/index.md

### Day 23, 24, 25, 26, and 27, Sunday, June 25, 2017, 11:02PM
Yes, for 5 days in a row, I dedicated time to finising an optional ggplot2 assignment. It took me a while to go over how ggplot2 works, but once I got the basics down, then I tweaked and tweaked until the plots looked professional enough. Lastly, I made sure to use a colorblind-friendly color palatte for the multi-panel graphs.

Here are the 2 PDF plots and the R script to make them:
https://github.com/emiliehwolf/ReproducibleResearchPlottingPractice/blob/master/plot0.pdf
https://github.com/emiliehwolf/ReproducibleResearchPlottingPractice/blob/master/plot1.pdf
https://github.com/emiliehwolf/ReproducibleResearchPlottingPractice/blob/master/analysis.R

### Day 28, Tuesday, June 27, 2017, 11:59PM
I did my best today. I watched some more lecture videos on reproducible research, knitr, and R markdown. I'm sleepy. Bedtime.

### Day 29, Wednesday, June 28, 2017, 5:35PM
I finished watching the week 2 videos on Coursera about knitr and passed the quiz. I read the requirements for the project assignment and downloaded the data into a new folder, but I haven't started a Git or R project for it yet. I'll do that tomorrow hopefully, but probably not since I work all day tomorrow for my new job.
https://github.com/rdpeng/courses/blob/master/05_ReproducibleResearch/knitr/knitr.pdf

### Day 30 and 31, Monday, July 3, 2017, 10:10AM
I listened to NSSD podcasts yesterday after work and today this morning. They talked about engineering data with Google spreadsheets and R for personal finances and taxes, which was really intriguing because for the first year of marriage, my husband and I kept track of all our income and expenses using Google Spreadsheet Form shortcuts on our phones. It got me thinking how I would go about collecting finance data again, but even tidier. What variables are important? What might missing data tell me? Is it possible my old data-entry design was fine? What happens if I put our first year of finance data into R? Does it need cleaning or manipulating before I can produce graphs in R? Should I start by entering all my current debts and assets so I can keep a running account total? And my husband's? I will definitely return to this once I've learned more on Statistical Inference. Perhaps I can just start a new entry form and spreadsheet for myself so I can get a new dataset to play with, then compare. Hmmmm. Okay, enough of that. Onto the assignment that was due yesterday.

**Update 4:20PM** Instead of focusing on the course assignment, I got carried away trying to use R Markdown and knitr to take some ggplot2 demo code and produce an entire HTML page with graphics and uploaded it to my website. Now I know how to quickly produce tutorials with R code. So cool! Check it out here: http://www.wolf.engineer/the-grammar.html

**Update 9:00PM** Another ggplot tutorial here: http://www.wolf.engineer/moreggplot2.html

### Day 32, Tuesday, July 4, 2017, 1:08PM
**Progress:** Yesterday and today I made a lot more headway on my programming assignment (that was due 2 days ago). 

**Thoughts:** R Markdown is so helpful. I'm really enjoying this assignment and how I'm using everything we've learned so far in the first 5 classes. My work feels more robust! I don't mind that I'm taking a long time, because I want to truly learn it!

**Link to latest work:** https://github.com/emiliehwolf/RepData_PeerAssessment1/blob/3b2e4c04386c036ef04c8e040ca3120a39bea905/PA1_template.Rmd

### Day 33 and 34, Thursday, July 6, 2017, 10:58PM
Bask in the glory that is my latest statistical analysis report for my Coursera class.

https://github.com/emiliehwolf/RepData_PeerAssessment1/blob/master/PA1_template.md

### Day 35, Saturday, July 8, 2017, 11:00PM
I watched some more lecture videos on reproducible research (week 3). I also figured out how to convert .Rmd to .md (in addition to .html, .pdf, and .docx.

https://github.com/emiliehwolf/ggplot2_examples/blob/master/moreggplot2.md
https://github.com/emiliehwolf/ggplot2_examples/blob/master/the-grammar.md

### Day 36 and 37, Tuesday, July 11, 2017, 11:29PM
Yesterday I listened to another NSSD podcast and finished watching lecture videos on how to use RPubs. Today I started the final peer review assignment for this course. 

Link to work: https://github.com/emiliehwolf/NOAA-Analysis-Report

I still want to learn Git flow, using branches and merges, so I can go back to old analyses and add more detailed plots the tidy way of version control.

### Day 38, Wednesday, July 12, 2017, 10:08PM
Today I worked on the NOAA-Analysis-Report some more. Chugging along...
Latest commit: https://github.com/emiliehwolf/NOAA-Analysis-Report/tree/5a9eca9fe7abfc0dc471d062de290a7e9456481d

### Day 39 and 40, Sunday, July 16, 2017, 10:02PM
Worked more on the NOAA assignment, but didn't finish before the deadline. Might have to switch sessions. =\

Latest commit: https://github.com/emiliehwolf/NOAA-Analysis-Report/blob/cf0fa0c12d1a9edce02c2ab359eaa31017262134/StormResearch.Rmd

### Day 41, 42, and 43, Wednesday, July 19, 2017 5:00PM
**Progress:** Monday night I finished the assignment and Tuesday and Wednesday I listened to podcasts and finished grading the other students on the NOAA Storm Research assignment.

**Thoughts:** I showed my report to a few strangers and they said it looks confusing. I agreed. Even though I know what's going on in the research and code, it doesn't look appealing at all to a laymen, which is disappointing because the whole reason I want to learn data science is to be able to simplify complex problems into engaging visuals. I want to make pretty infographics and websites and apps... not boring reports with synopses, abstracts, and jargon. The data manipulation code and the reproducible research report are necessary to validate my work, but they cannot stand alone. I want to appeal to the masses, not other statisticians. I want to produce vibrant work that inspires others to become data scientists. I'm here to creatively express ideas, not bore people to sleep! LOL

### Day 44, Sunday, July 30, 2017, 9:58PM
Today I started the Coursera class Statistical Inference. It's being taught by a different professor and so the style is quite different. Professor Caffo says to not feel bad if we switch sessions and join a later class so as to fully understand the materials. After starting on Probability, I realized that Caffo was speaking awefully fast, so I decided to go to Khan Academy and get a review of the basics and vocabulary. I watched videos on probablity for about an hour, but just as I got into sets, subsets, and unions, I fell asleep. And I slept for 5 hours! Which is crazy because I thought I caught up on sleep the last 3 days!

Anyway, I am going to take my time and fully immerse myself in higher math so I can get the most out of this Statistical Inference class. I'm excited to be diving back into the type of academics I remember from University!

### Day 45, Saturday, August 5, 2017, 6PM
**Progress:** Watched Khan Academy videos on probability. Then read an R-bloggers article on [basic set theory in R (unions, intersections, and subsets)](https://www.r-bloggers.com/set-operations-unions-and-intersections-in-r/).

**Thoughts:** I remember using Wolfram Alpha a lot in college to aid with my study. I just realized that R programming is like the upgrade version of WolframAlpha that can calculate higher math on big, complex datasets. I'm loving where data science is going. I hope as I look over the horizon to the future, I can see farther and further. To think I've been using computers since AmericaOnLine and 28K dialup speeds. To think that free access to the internet has provided me the best education. What's next?! What amazing superpower talent am I going to acquire that takes my previous skills and combines them?

![statistics.png](http://www.wolf.engineer/wp-content/uploads/2017/08/statistics.png)

**More Notes on Set Operations:** These come from base R...

union(x, y)
intersect(x, y)
setdiff(x, y)
setequal(x, y)

is.element(el, set) --- is.element(x, y) is identical to x %in% y.
